{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c6b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import plotly.io as pio\n",
    "import streamlit as st\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from utils.manager.login import *\n",
    "from utils.inputs.validation import *\n",
    "from utils.inputs.ads import *\n",
    "from utils.modeling.general import *\n",
    "from utils.modeling.skforecast_utils import *\n",
    "from utils.modeling.sktime_utils import *\n",
    "from utils.modeling.plot import *\n",
    "\n",
    "# Set up the logging configuration for cmdstanpy\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Add NullHandler with CRITICAL log level\n",
    "null_handler = logging.NullHandler()\n",
    "null_handler.setLevel(logging.CRITICAL)\n",
    "logger.addHandler(null_handler)\n",
    "\n",
    "# Add StreamHandler with INFO log level\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ae5d9",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d814092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropdown for Country\n",
    "country_name = \"CA\"\n",
    "\n",
    "# Add dropdown for frequency\n",
    "forecast_freq = \"B\"\n",
    "\n",
    "# Add dropdown for data selection\n",
    "data_selection = True\n",
    "\n",
    "# Add dropdown for data selection\n",
    "external_features = True\n",
    "\n",
    "# Add file uploader to the sidebar\n",
    "uploaded_historical_file = 'Agency Services_multi.csv'\n",
    "\n",
    "if external_features:\n",
    "    uploaded_forecast_file = 'Agency Services_multi_forecast.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397d1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if forecast_freq == \"D\":\n",
    "    forecast_period = 92\n",
    "elif forecast_freq == \"B\":\n",
    "    forecast_period = 66\n",
    "elif forecast_freq == \"W\":\n",
    "    forecast_period = 26\n",
    "elif forecast_freq == \"M\":\n",
    "    forecast_period = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631f99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize these selections into a dictionary\n",
    "run_params = {\n",
    "    \"country_name\": country_name,\n",
    "    \"forecast_freq\": forecast_freq,\n",
    "    \"forecast_period\": forecast_period,\n",
    "    \"data_selection\": data_selection,\n",
    "    \"external_features\": external_features,\n",
    "    \"weekend_weight\": 5,\n",
    "    \"holiday_weight\": 10,\n",
    "    \"metric_key\": \"mspe\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b710081",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb8549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Validate the input file\n",
    "    historical_df = validate_input_file(uploaded_historical_file, external_features)\n",
    "    logging.info(f\"Historical Data Size: {historical_df.shape}\")\n",
    "    # Find the min data for optimal train data\n",
    "    run_params[\"historical_start_date\"] = historical_df['ds'].min()\n",
    "    run_params[\"historical_end_date\"] = historical_df['ds'].max()\n",
    "    run_params[\"forecast_start_date\"] = historical_df['ds'].max() + pd.Timedelta(days=1)\n",
    "    run_params[\"forecast_end_date\"] = historical_df['ds'].max() + pd.Timedelta(days=run_params[\"forecast_period\"])\n",
    "    \n",
    "except Exception as e:\n",
    "    # Log this exception or handle it further up the call stack\n",
    "    raise Exception(f\"An error occurred while validating the uploaded historical data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698ebc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>Insurance_Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>9315434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>9315434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>9315434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>228</td>\n",
       "      <td>9315434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>186</td>\n",
       "      <td>9315434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>265</td>\n",
       "      <td>17681592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>247</td>\n",
       "      <td>17681592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>2023-07-29</td>\n",
       "      <td>0</td>\n",
       "      <td>17681592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>2023-07-30</td>\n",
       "      <td>0</td>\n",
       "      <td>17681592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>327</td>\n",
       "      <td>17681592.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds    y  Insurance_Actual\n",
       "0   2021-01-01    0         9315434.0\n",
       "1   2021-01-02    0         9315434.0\n",
       "2   2021-01-03    0         9315434.0\n",
       "3   2021-01-04  228         9315434.0\n",
       "4   2021-01-05  186         9315434.0\n",
       "..         ...  ...               ...\n",
       "937 2023-07-27  265        17681592.0\n",
       "938 2023-07-28  247        17681592.0\n",
       "939 2023-07-29    0        17681592.0\n",
       "940 2023-07-30    0        17681592.0\n",
       "941 2023-07-31  327        17681592.0\n",
       "\n",
       "[942 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f7d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if run_params[\"external_features\"]:\n",
    "        # Validate the input file\n",
    "        forecast_df = validate_input_file(uploaded_forecast_file, external_features)\n",
    "        logging.info(f\"Forecast Data Size: {forecast_df.shape}\")\n",
    "        \n",
    "        assert forecast_df['ds'].min() == run_params[\"forecast_start_date\"], 'Forecast Start Data is not aligned with Historical End Date'\n",
    "        \n",
    "        assert forecast_df['ds'].max() >= run_params[\"forecast_end_date\"], 'Forecast Data is not available for entire Forecast Period'\n",
    "        \n",
    "    else:\n",
    "        forecast_df = pd.DataFrame(columns=historical_df.columns)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Log this exception or handle it further up the call stack\n",
    "    raise Exception(f\"An error occurred while validating the uploaded forecast data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b206667d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>Insurance_Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19162757.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19162757.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-08-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19162757.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19162757.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19162757.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2024-11-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31824538.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2024-11-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31824538.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31824538.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31824538.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35254798.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds    y  Insurance_Actual\n",
       "0   2023-08-01  0.0       19162757.00\n",
       "1   2023-08-02  0.0       19162757.00\n",
       "2   2023-08-03  0.0       19162757.00\n",
       "3   2023-08-04  0.0       19162757.00\n",
       "4   2023-08-05  0.0       19162757.00\n",
       "..         ...  ...               ...\n",
       "484 2024-11-27  0.0       31824538.23\n",
       "485 2024-11-28  0.0       31824538.23\n",
       "486 2024-11-29  0.0       31824538.23\n",
       "487 2024-11-30  0.0       31824538.23\n",
       "488 2024-12-01  0.0       35254798.93\n",
       "\n",
       "[489 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86901c29",
   "metadata": {},
   "source": [
    "## Automated Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44662db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if data_selection:\n",
    "        \n",
    "        # Find optimal window \n",
    "        optimal_window_size = find_optimal_window(historical_df)\n",
    "            \n",
    "        logging.info(f\"Optimal Window Size: {optimal_window_size}\")\n",
    "\n",
    "        # Add 180 days for feature engineering to optimal window\n",
    "        optimal_window_size += 180\n",
    "\n",
    "    else:\n",
    "        optimal_window_size = len(historical_df)\n",
    "        \n",
    "except Exception as e:\n",
    "    # Log this exception or handle it further up the call stack\n",
    "    raise Exception(f\"An error occurred while finding the optimal window: {str(e)}\")\n",
    "\n",
    "    \n",
    "# Truncate the train set based on optimal window\n",
    "optimal_df = historical_df[-optimal_window_size:].copy(deep=True)\n",
    "    \n",
    "logging.info(f\"Optimal Train Data Size: {optimal_df.shape}\")\n",
    "\n",
    "# Find the min data for optimal train data\n",
    "run_params[\"optimal_window_size\"] = optimal_window_size\n",
    "run_params[\"optimal_window_start_date\"] = optimal_df['ds'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a713cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_window_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603e0fd",
   "metadata": {},
   "source": [
    "## Final Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca03407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Validate column counts based on whether external features are used\n",
    "    if external_features:\n",
    "        assert optimal_df.shape[1] > 2 and forecast_df.shape[1] > 2, \"Uploaded Historical or Forecast Data does have required number of columns!\"\n",
    "    else:\n",
    "        assert optimal_df.shape[1] == 2 and forecast_df.shape[1] == 2, \"Uploaded Historical or Forecast Data does have required number of columns!\"\n",
    "    # Ensure non-empty data structure\n",
    "    assert optimal_df.shape[1] > 0, \"Uploaded Historical Data does not have enough rows!\"\n",
    "    # Ensure same number of columns\n",
    "    assert optimal_df.shape[1] == forecast_df.shape[1], \"Uploaded Historical and Forecast Data do not have the same number of columns\"\n",
    "except Exception as e:\n",
    "    raise ValueError(\"Invalid input data format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9624e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the exogenous variables from the train data\n",
    "run_params[\"exog_cols\"] = list((optimal_df.columns).difference(['y', 'ds']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98107feb",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eeb81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Generate date features\n",
    "    optimal_df = resample_dataframe(optimal_df, run_params[\"forecast_freq\"])\n",
    "    forecast_df = resample_dataframe(forecast_df, run_params[\"forecast_freq\"])\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Failed to set the data frequency to {forecast_freq}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "565478ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Generate date features\n",
    "    optimal_df = generate_date_features(optimal_df, forecast_freq, country_name)\n",
    "    forecast_df = generate_date_features(forecast_df, forecast_freq, country_name)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to generate features using 'ds': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db27b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the exogenous variables from the train data\n",
    "run_params[\"exog_cols_all\"]  = list((optimal_df.columns).difference(['y', 'ds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79b9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    initial_window_size, lag_window_range, rolling_window_range, test_size, test_steps = determine_params(forecast_freq)\n",
    "    logger.info(f\"Initial Window Size: {initial_window_size}, Lag Window Range: {lag_window_range}\")\n",
    "    logger.info(f\"Test Size: {test_size}, Test Steps: {test_steps}\")\n",
    "except Exception as e:\n",
    "    raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93f763c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params.update({\n",
    "    \"initial_window_size\": initial_window_size,\n",
    "    \"lag_window_range\": lag_window_range,\n",
    "    \"rolling_window_range\": rolling_window_range,\n",
    "    \"test_size\": test_size,\n",
    "    \"test_steps\": test_steps\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fddc05",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee84b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    test_df = optimal_df[-test_size:].copy(deep=True)\n",
    "    test_df = test_df.set_index('ds').resample(run_params[\"forecast_freq\"]).sum()\n",
    "    test_df = test_df.fillna(0)\n",
    "    \n",
    "    train_df = optimal_df[:-test_size].copy(deep=True)\n",
    "    train_df = train_df.set_index('ds').resample(run_params[\"forecast_freq\"]).sum()\n",
    "    train_df = train_df.fillna(0)\n",
    "    \n",
    "    assert len(train_df) + len(test_df) == len(optimal_df)\n",
    "    \n",
    "    run_params[\"train_start_date\"] = train_df.index.min()\n",
    "    run_params[\"train_end_date\"] = train_df.index.max()\n",
    "    \n",
    "    run_params[\"test_start_date\"] = test_df.index.min()\n",
    "    run_params[\"test_end_date\"] = test_df.index.max()\n",
    "    \n",
    "    optimal_df = optimal_df.set_index('ds').resample(run_params[\"forecast_freq\"]).sum()\n",
    "    optimal_df = optimal_df.fillna(0)\n",
    "    \n",
    "    forecast_df = forecast_df.set_index('ds').resample(run_params[\"forecast_freq\"]).sum()\n",
    "    forecast_df = forecast_df.fillna(0)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to split into train and test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb83819",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "485e2c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "2024-06-23 16:12:32,774 - prophet - INFO - Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "2024-06-23 16:12:32,776 - prophet - INFO - Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/8ngtnpoh.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/p6wmw5_n.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/abhishekagarwal/opt/anaconda3/lib/python3.9/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=65108', 'data', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/8ngtnpoh.json', 'init=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/p6wmw5_n.json', 'output', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/prophet_modelr7llmd20/prophet_model-20240623161232.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "16:12:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "2024-06-23 16:12:32,808 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:12:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "2024-06-23 16:12:32,843 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "2024-06-23 16:12:32,864 - prophet - INFO - Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "2024-06-23 16:12:32,865 - prophet - INFO - Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/la2mfmax.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/e7or09fc.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/abhishekagarwal/opt/anaconda3/lib/python3.9/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=40312', 'data', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/la2mfmax.json', 'init=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/e7or09fc.json', 'output', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/prophet_modelxvpihqz4/prophet_model-20240623161232.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "16:12:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "2024-06-23 16:12:32,896 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:12:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "2024-06-23 16:12:32,933 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9f4b0d0a134ddeb48f0380d5f24339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc736e5b7e5f431283f985dc2e9fb1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d2ad50d8f84a9bb6901bbf4fc9100c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b078114e4b644b499b6bc3970735463b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89efcf7e1c0465c93cbc24496bcee4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e84b4a8eae4011b69481718258e4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ea3700f0294706bddfeb75570ef34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52ed27ea6a146d49f85fa1ebc4fd194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eaa77f9200d48a9be59286ee462f57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a198c4165db4d458f0ec152265d07fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_dir = 'utils/modeling'\n",
    "\n",
    "model_types = {\n",
    "    'prophet': 'sktime',\n",
    "    'naive': 'sktime',\n",
    "    'random_forest': 'skforecast',\n",
    "    'xgboost': 'skforecast'\n",
    "}\n",
    "\n",
    "search_results = {}\n",
    "\n",
    "for model_type, package_type in model_types.items():\n",
    "    # Load parameters for grid search\n",
    "    model, param_grid = load_model_params_and_create_instance(model_type, current_dir)\n",
    "    \n",
    "    if package_type == 'sktime':\n",
    "        # Find best model\n",
    "        best_configuration, all_results, best_model = find_best_model_sktime(\n",
    "            train_df['y'], run_params, model, param_grid\n",
    "        )\n",
    "    \n",
    "    elif package_type == 'skforecast':\n",
    "        # Find best model\n",
    "        best_configuration, all_results, best_model = find_best_model_skforecast(\n",
    "            lag_window_range, model, train_df, param_grid, run_params\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Unknown package type!')\n",
    "    \n",
    "    # Save best model and config\n",
    "    search_results[model_type] = {\n",
    "        'best_model': best_model,\n",
    "        'best_configuration': best_configuration,\n",
    "        'all_results': all_results,\n",
    "        'package_type': package_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af73618d",
   "metadata": {},
   "source": [
    "## Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c87a366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "2024-06-23 16:12:42,969 - prophet - INFO - Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "2024-06-23 16:12:42,969 - prophet - INFO - Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/wzt3thvw.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/l0bwfsx4.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/abhishekagarwal/opt/anaconda3/lib/python3.9/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=34765', 'data', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/wzt3thvw.json', 'init=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/l0bwfsx4.json', 'output', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/prophet_model6o754zza/prophet_model-20240623161242.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "16:12:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "2024-06-23 16:12:42,998 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:12:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "2024-06-23 16:12:43,037 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "test_eval = {}\n",
    "\n",
    "for model_type, model_results in search_results.items():\n",
    "    if model_results['package_type'] == 'sktime':\n",
    "        best_model = search_results[model_type]['best_model']\n",
    "        best_model.fit(y=train_df['y'])\n",
    "        predictions_df = generate_forecast_sktime(best_model, len(test_df))\n",
    "    elif model_results['package_type'] == 'skforecast':\n",
    "        best_model = search_results[model_type]['best_model']\n",
    "        best_model.fit(y=train_df['y'], exog=train_df[run_params[\"exog_cols_all\"]])\n",
    "        predictions_df = generate_forecast_skforecast(best_model, run_params, train_df['y'],\n",
    "                                                      test_df.drop('y', axis=1),\n",
    "                                                      run_params[\"test_start_date\"],\n",
    "                                                      len(test_df))\n",
    "    else:\n",
    "        raise Exception('Unknown package type!')\n",
    "\n",
    "    test_eval[model_type] = compute_metrics(predictions_df.merge(test_df.reset_index()), train_df[\"y\"])\n",
    "    \n",
    "# Convert the list of dictionaries into a DataFrame for easy manipulation\n",
    "metrics_df = pd.DataFrame(test_eval).T\n",
    "\n",
    "# Round off the values in the DataFrame to 3 decimal places for better readability\n",
    "metrics_df = metrics_df.round(3)\n",
    "\n",
    "# Sort the DataFrame based on the performance metrics in the order of preference\n",
    "# MASE > RMSSE > Coverage > MAPE > RMSPE\n",
    "metric_order = ['MASE', 'RMSSE', 'Coverage', 'MAPE', 'RMSPE']\n",
    "ascending_order = [True, True, False, True, True]\n",
    "\n",
    "metrics_df = metrics_df.sort_values(by=metric_order, ascending=ascending_order).reset_index()\n",
    "\n",
    "metrics_df.rename(columns={'index': 'Model'}, inplace=True)\n",
    "metrics_df['Model'] = metrics_df['Model'].str.replace('_', ' ').str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb141b",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06723a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "2024-06-23 16:12:46,338 - prophet - INFO - Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "2024-06-23 16:12:46,338 - prophet - INFO - Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/um6yaq_u.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/is6rc0ew.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/abhishekagarwal/opt/anaconda3/lib/python3.9/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=65862', 'data', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/um6yaq_u.json', 'init=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/is6rc0ew.json', 'output', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmprrsqqrc_/prophet_modeltkrw2gd_/prophet_model-20240623161246.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "16:12:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "2024-06-23 16:12:46,366 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:12:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "2024-06-23 16:12:46,411 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "forecasts_all = {}\n",
    "\n",
    "for model_type, model_results in search_results.items():\n",
    "    if model_results['package_type'] == 'sktime':\n",
    "        best_model = search_results[model_type]['best_model']\n",
    "        best_model.fit(y=optimal_df['y'])\n",
    "        predictions = generate_forecast_sktime(best_model, run_params['forecast_period'])\n",
    "    elif model_results['package_type'] == 'skforecast':\n",
    "        best_model = search_results[model_type]['best_model']\n",
    "        best_model.fit(y=optimal_df['y'], exog=optimal_df[run_params[\"exog_cols_all\"]])\n",
    "        forecasts_all[model_type] = generate_forecast_skforecast(best_model, run_params, optimal_df['y'],\n",
    "                                                                 forecast_df.drop('y', axis=1),\n",
    "                                                                 run_params[\"forecast_start_date\"],\n",
    "                                                                 run_params['forecast_period'])\n",
    "    else:\n",
    "        raise Exception('Unknown package type!')\n",
    "        \n",
    "    forecasts_all[model_type] = predictions.head(run_params['forecast_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b444f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'prophet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant data from the historical and forecast DataFrames\n",
    "historical_data = optimal_df.reset_index()[['ds', 'y']]\n",
    "forecast_data = forecasts_all[model_type][['ds', 'y_pred', 'min_pred', 'max_pred']]\n",
    "fig = plot_forecasts(historical_data, forecast_data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aabdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract features from the Date column.\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"Extracting date features\")\n",
    "\n",
    "    # Extract various features from the Date column\n",
    "    df[\"Year\"] = df[\"Date\"].dt.year\n",
    "    df[\"Quarter\"] = df[\"Date\"].dt.quarter\n",
    "    df[\"Month\"] = df[\"Date\"].dt.strftime(\"%B\")\n",
    "    df[\"Weekday Number\"] = df[\"Date\"].dt.weekday\n",
    "    df[\"Day\"] = df[\"Date\"].dt.strftime(\"%A\")\n",
    "    df[\"Month Week\"] = df[\"Date\"].dt.isocalendar().week\n",
    "\n",
    "    logger.info(\"Date features extracted\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e96308",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data['type'] = 0 # 1 for historical\n",
    "forecast_data['type'] = 1  # 1 for forecast\n",
    "# Prepare forecast data\n",
    "forecast_data['y'] = forecast_data['y_pred']\n",
    "forecast_data = forecast_data.drop(columns=['y_pred'])\n",
    "\n",
    "# Merge the two DataFrames\n",
    "combined_data = pd.concat([historical_data, forecast_data], sort=True)\n",
    "\n",
    "# Sort by date if necessary\n",
    "combined_data = combined_data.sort_values(by='ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_types = ['month', 'day_of_week', 'week_of_year']\n",
    "agg_types = ['mean', 'sum', 'min', 'max']\n",
    "selected_freq = freq_types[1]\n",
    "selected_agg = agg_types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c45cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = create_pivot_table(combined_data, selected_freq, selected_agg)\n",
    "fig = plot_time_series(pivot_table)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
