{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c6b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import plotly.io as pio\n",
    "import streamlit as st\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from utils.manager.login import *\n",
    "from utils.inputs.validation import *\n",
    "from utils.inputs.ads import *\n",
    "from utils.modeling.general import *\n",
    "from utils.modeling.skforecast_utils import *\n",
    "from utils.modeling.sktime_utils import *\n",
    "from utils.modeling.plot import *\n",
    "\n",
    "# Set up the logging configuration for cmdstanpy\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Add NullHandler with CRITICAL log level\n",
    "null_handler = logging.NullHandler()\n",
    "null_handler.setLevel(logging.CRITICAL)\n",
    "logger.addHandler(null_handler)\n",
    "\n",
    "# Add StreamHandler with INFO log level\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ae5d9",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d814092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropdown for Country\n",
    "country_name = \"CA\"\n",
    "\n",
    "# Add dropdown for frequency\n",
    "forecast_freq = \"B\"\n",
    "\n",
    "# Add dropdown for data selection\n",
    "data_selection = True\n",
    "\n",
    "# Add dropdown for data selection\n",
    "external_features = False\n",
    "\n",
    "# Add file uploader to the sidebar\n",
    "uploaded_historical_file = 'Agency Services.csv' #'Agency Services_multi.csv'\n",
    "\n",
    "if external_features:\n",
    "    uploaded_forecast_file = 'Agency Services_multi_forecast.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "397d1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if forecast_freq == \"D\":\n",
    "    forecast_period = 92\n",
    "elif forecast_freq == \"B\":\n",
    "    forecast_period = 66\n",
    "elif forecast_freq == \"W\":\n",
    "    forecast_period = 26\n",
    "elif forecast_freq == \"M\":\n",
    "    forecast_period = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d04be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize these selections into a dictionary\n",
    "run_params = {\n",
    "    \"country_name\": country_name,\n",
    "    \"forecast_freq\": forecast_freq,\n",
    "    \"forecast_period\": forecast_period,\n",
    "    \"data_selection\": data_selection,\n",
    "    \"external_features\": external_features,\n",
    "    \"weekend_weight\": 5,\n",
    "    \"holiday_weight\": 10,\n",
    "    \"metric_key\": \"mspe\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b710081",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb8549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Validate the input file\n",
    "    historical_df = validate_input_file(uploaded_historical_file, run_params[\"external_features\"])\n",
    "    logging.info(f\"Historical Data Size: {historical_df.shape}\")\n",
    "    # Find the min data for optimal train data\n",
    "    run_params[\"historical_start_date\"] = historical_df['ds'].min()\n",
    "    run_params[\"historical_end_date\"] = historical_df['ds'].max()\n",
    "    run_params[\"forecast_start_date\"] = historical_df['ds'].max() + pd.Timedelta(days=1)\n",
    "    run_params[\"forecast_end_date\"] = calculate_end_date(run_params)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Log this exception or handle it further up the call stack\n",
    "    raise Exception(f\"An error occurred while validating the uploaded historical data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db6cac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds      y\n",
       "0   2018-01-01    0.0\n",
       "1   2018-01-02  367.0\n",
       "2   2018-01-03  391.0\n",
       "3   2018-01-04  431.0\n",
       "4   2018-01-05  395.0\n",
       "..         ...    ...\n",
       "360 2018-12-27  280.0\n",
       "361 2018-12-28  278.0\n",
       "362 2018-12-29    0.0\n",
       "363 2018-12-30    0.0\n",
       "364 2018-12-31  299.0\n",
       "\n",
       "[365 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eea13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if run_params[\"external_features\"]:\n",
    "        # Validate the input file\n",
    "        forecast_df = validate_input_file(uploaded_forecast_file, run_params[\"external_features\"])\n",
    "        logging.info(f\"Forecast Data Size: {forecast_df.shape}\")\n",
    "        \n",
    "        assert forecast_df['ds'].min() == run_params[\"forecast_start_date\"], 'Forecast Start Data is not aligned with Historical End Date'\n",
    "        \n",
    "        assert forecast_df['ds'].max() >= run_params[\"forecast_end_date\"], 'Forecast Data is not available for entire Forecast Period'\n",
    "        \n",
    "    else:\n",
    "        forecast_df = pd.DataFrame(columns=historical_df.columns)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Log this exception or handle it further up the call stack\n",
    "    raise Exception(f\"An error occurred while validating the uploaded forecast data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c98d1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ds, y]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043cf01",
   "metadata": {},
   "source": [
    "## Automated Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44662db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if run_params[\"data_selection\"]:\n",
    "        \n",
    "        # Find optimal window \n",
    "        optimal_window_size = find_optimal_window(historical_df)\n",
    "            \n",
    "        logging.info(f\"Optimal Window Size: {optimal_window_size}\")\n",
    "\n",
    "        # Add 180 days for feature engineering to optimal window\n",
    "        optimal_window_size += 180\n",
    "\n",
    "    else:\n",
    "        optimal_window_size = len(historical_df)\n",
    "        \n",
    "except Exception as e:\n",
    "    # Log this exception or handle it further up the call stack\n",
    "    raise Exception(f\"An error occurred while finding the optimal window: {str(e)}\")\n",
    "\n",
    "    \n",
    "# Truncate the train set based on optimal window\n",
    "optimal_df = historical_df[-optimal_window_size:].copy(deep=True)\n",
    "    \n",
    "logging.info(f\"Optimal Train Data Size: {optimal_df.shape}\")\n",
    "\n",
    "# Find the min data for optimal train data\n",
    "run_params[\"optimal_window_size\"] = optimal_window_size\n",
    "run_params[\"optimal_window_start_date\"] = optimal_df['ds'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32c9d3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_window_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2479a2ac",
   "metadata": {},
   "source": [
    "## Final Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25fe75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_params[\"external_features\"]:\n",
    "    date_range = pd.date_range(start=run_params['forecast_start_date'],\n",
    "                                               end=run_params['forecast_end_date'])\n",
    "    forecast_df['ds'] = date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "274fa89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Validate column counts based on whether external features are used\n",
    "    if run_params[\"external_features\"]:\n",
    "        assert optimal_df.shape[1] > 2 and forecast_df.shape[1] > 2, \"Uploaded Historical or Forecast Data does have required number of columns!\"\n",
    "    else:\n",
    "        assert optimal_df.shape[1] == 2 and forecast_df.shape[1] == 2, \"Uploaded Historical or Forecast Data does have required number of columns!\"\n",
    "    # Ensure non-empty data structure\n",
    "    assert optimal_df.shape[0] > 0, \"Uploaded Historical Data does not have enough rows!\"\n",
    "    assert forecast_df.shape[0] >= run_params[\"forecast_period\"], \"Uploaded Historical and Forecast Data do not have the same number of columns\"\n",
    "    # Ensure same number of columns\n",
    "    assert optimal_df.shape[1] == forecast_df.shape[1], \"Uploaded Historical and Forecast Data do not have the same number of columns\"\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Invalid input data format: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9187ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the exogenous variables from the train data\n",
    "run_params[\"exog_cols\"] = list((optimal_df.columns).difference(['y', 'ds']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8a84b",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55348fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Generate date features\n",
    "    optimal_df = resample_dataframe(optimal_df, run_params[\"forecast_freq\"])\n",
    "    forecast_df = resample_dataframe(forecast_df, run_params[\"forecast_freq\"])\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Failed to set the data frequency to {forecast_freq}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "765df0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Generate date features\n",
    "    optimal_df = generate_date_features(optimal_df, forecast_freq, country_name)\n",
    "    forecast_df = generate_date_features(forecast_df, forecast_freq, country_name)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to generate features using 'ds': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14d7549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the exogenous variables from the train data\n",
    "run_params[\"exog_cols_all\"]  = list((optimal_df.columns).difference(['y', 'ds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a19baaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    initial_window_size, lag_window_range, rolling_window_range, test_size, test_steps = determine_params(forecast_freq)\n",
    "    logger.info(f\"Initial Window Size: {initial_window_size}, Lag Window Range: {lag_window_range}\")\n",
    "    logger.info(f\"Test Size: {test_size}, Test Steps: {test_steps}\")\n",
    "except Exception as e:\n",
    "    raise Exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a3752d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params.update({\n",
    "    \"initial_window_size\": initial_window_size,\n",
    "    \"lag_window_range\": lag_window_range,\n",
    "    \"rolling_window_range\": rolling_window_range,\n",
    "    \"test_size\": test_size,\n",
    "    \"test_steps\": test_steps\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8eed90",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d5f10b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    test_df = optimal_df[-test_size:].copy(deep=True)\n",
    "    test_df = test_df.set_index('ds').resample(run_params[\"forecast_freq\"]).sum()\n",
    "    test_df = test_df.fillna(0)\n",
    "    \n",
    "    train_df = optimal_df[:-test_size].copy(deep=True)\n",
    "    train_df = train_df.set_index('ds').resample(run_params[\"forecast_freq\"]).sum()\n",
    "    train_df = train_df.fillna(0)\n",
    "    \n",
    "    assert len(train_df) + len(test_df) == len(optimal_df)\n",
    "    \n",
    "    run_params[\"train_start_date\"] = train_df.index.min()\n",
    "    run_params[\"train_end_date\"] = train_df.index.max()\n",
    "    \n",
    "    run_params[\"test_start_date\"] = test_df.index.min()\n",
    "    run_params[\"test_end_date\"] = test_df.index.max()\n",
    "    \n",
    "    optimal_df = optimal_df.set_index('ds').resample(run_params[\"forecast_freq\"]).sum()\n",
    "    optimal_df = optimal_df.fillna(0)\n",
    "    \n",
    "    forecast_df = forecast_df.set_index('ds').resample(run_params[\"forecast_freq\"]).sum()\n",
    "    forecast_df = forecast_df.fillna(0)\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to split into train and test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e7f4a",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6f4b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "2024-06-24 07:09:51,196 - prophet - INFO - Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "2024-06-24 07:09:51,198 - prophet - INFO - Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/n06xhjs_.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/7npvzdbw.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/abhishekagarwal/opt/anaconda3/lib/python3.9/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=75124', 'data', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/n06xhjs_.json', 'init=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/7npvzdbw.json', 'output', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/prophet_model1un0kh_2/prophet_model-20240624070951.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "07:09:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "2024-06-24 07:09:51,224 - cmdstanpy - INFO - Chain [1] start processing\n",
      "07:09:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "2024-06-24 07:09:51,256 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "2024-06-24 07:09:51,276 - prophet - INFO - Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "2024-06-24 07:09:51,277 - prophet - INFO - Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/aitbb5th.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/jyt3jli5.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/abhishekagarwal/opt/anaconda3/lib/python3.9/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=43178', 'data', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/aitbb5th.json', 'init=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/jyt3jli5.json', 'output', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/prophet_modelt6whyk2s/prophet_model-20240624070951.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "07:09:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "2024-06-24 07:09:51,300 - cmdstanpy - INFO - Chain [1] start processing\n",
      "07:09:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "2024-06-24 07:09:51,332 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abc3a4dee6e4f50bed291b0bcd775b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650274a05ba245f9ad352ec09cb5663e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e51ccfe8d9423c82a9bdce81bc1080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af2bd2a09c34beb80c5002e81ced8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc69f05082484f508756ee1b811cc69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642d84749abb4333af45101b5fec3eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a68d592626146c0a6e228c92594ae92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b813cf5efe4918a2df89295325508e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9f10a78c1949009f227cd68de80751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 1.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb3248762d245569f6306778334eca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_dir = 'utils/modeling'\n",
    "\n",
    "model_types = {\n",
    "    'prophet': 'sktime',\n",
    "    'naive': 'sktime',\n",
    "    'random_forest': 'skforecast',\n",
    "    'xgboost': 'skforecast'\n",
    "}\n",
    "\n",
    "search_results = {}\n",
    "\n",
    "for model_type, package_type in model_types.items():\n",
    "    # Load parameters for grid search\n",
    "    model, param_grid = load_model_params_and_create_instance(model_type, current_dir)\n",
    "    \n",
    "    if package_type == 'sktime':\n",
    "        # Find best model\n",
    "        best_configuration, all_results, best_model = find_best_model_sktime(\n",
    "            train_df['y'], run_params, model, param_grid\n",
    "        )\n",
    "    \n",
    "    elif package_type == 'skforecast':\n",
    "        # Find best model\n",
    "        best_configuration, all_results, best_model = find_best_model_skforecast(\n",
    "            lag_window_range, model, train_df, param_grid, run_params\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Unknown package type!')\n",
    "    \n",
    "    # Save best model and config\n",
    "    search_results[model_type] = {\n",
    "        'best_model': best_model,\n",
    "        'best_configuration': best_configuration,\n",
    "        'all_results': all_results,\n",
    "        'package_type': package_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110d18a",
   "metadata": {},
   "source": [
    "## Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d69be03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "2024-06-24 07:10:06,495 - prophet - INFO - Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "2024-06-24 07:10:06,496 - prophet - INFO - Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/a665km8g.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/ibbfkdow.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/abhishekagarwal/opt/anaconda3/lib/python3.9/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=22327', 'data', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/a665km8g.json', 'init=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/ibbfkdow.json', 'output', 'file=/var/folders/4t/nrkfp1595tb366616gpf9d540000gn/T/tmp3xueyhc7/prophet_modeln5pekhn2/prophet_model-20240624071006.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "07:10:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "2024-06-24 07:10:06,525 - cmdstanpy - INFO - Chain [1] start processing\n",
      "07:10:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "2024-06-24 07:10:06,559 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "test_eval = {}\n",
    "\n",
    "for model_type, model_results in search_results.items():\n",
    "    if model_results['package_type'] == 'sktime':\n",
    "        best_model = search_results[model_type]['best_model']\n",
    "        best_model.fit(y=train_df['y'])\n",
    "        predictions_df = generate_forecast_sktime(best_model, len(test_df))\n",
    "    elif model_results['package_type'] == 'skforecast':\n",
    "        best_model = search_results[model_type]['best_model']\n",
    "        best_model.fit(y=train_df['y'], exog=train_df[run_params[\"exog_cols_all\"]])\n",
    "        predictions_df = generate_forecast_skforecast(best_model, run_params, train_df['y'],\n",
    "                                                      test_df.drop('y', axis=1),\n",
    "                                                      run_params[\"test_start_date\"],\n",
    "                                                      len(test_df))\n",
    "    else:\n",
    "        raise Exception('Unknown package type!')\n",
    "        \n",
    "    predictions_df = predictions_df.merge(test_df.reset_index())\n",
    "    predictions_df['y'] = predictions_df['y'].apply(lambda x: 1 if x == 0 else x)\n",
    "    predictions_df['y_pred'] = predictions_df['y_pred'].apply(lambda x: 1 if x == 0 else x)\n",
    "    \n",
    "    test_eval[model_type] = compute_metrics(predictions_df, train_df[\"y\"])\n",
    "    \n",
    "# Convert the list of dictionaries into a DataFrame for easy manipulation\n",
    "metrics_df = pd.DataFrame(test_eval).T\n",
    "\n",
    "# Round off the values in the DataFrame to 3 decimal places for better readability\n",
    "metrics_df = metrics_df.round(3)\n",
    "\n",
    "# Sort the DataFrame based on the performance metrics in the order of preference\n",
    "# MASE > RMSSE > Coverage > MAPE > RMSPE\n",
    "metric_order = ['MASE', 'RMSSE', 'Coverage', 'MAPE', 'RMSPE']\n",
    "ascending_order = [True, True, False, True, True]\n",
    "\n",
    "metrics_df = metrics_df.sort_values(by=metric_order, ascending=ascending_order).reset_index()\n",
    "\n",
    "metrics_df.rename(columns={'index': 'Model'}, inplace=True)\n",
    "metrics_df['Model'] = metrics_df['Model'].str.replace('_', ' ').str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a648f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSPE</th>\n",
       "      <th>MASE</th>\n",
       "      <th>RMSSE</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>6.286</td>\n",
       "      <td>26.556</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prophet</td>\n",
       "      <td>17.875</td>\n",
       "      <td>77.019</td>\n",
       "      <td>0.969</td>\n",
       "      <td>1.079</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>16.016</td>\n",
       "      <td>68.751</td>\n",
       "      <td>1.009</td>\n",
       "      <td>1.027</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xgboost</td>\n",
       "      <td>7.875</td>\n",
       "      <td>32.869</td>\n",
       "      <td>1.738</td>\n",
       "      <td>1.135</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model    MAPE   RMSPE   MASE  RMSSE  Coverage\n",
       "0  Random Forest   6.286  26.556  0.761  0.614      0.75\n",
       "1        Prophet  17.875  77.019  0.969  1.079      0.85\n",
       "2          Naive  16.016  68.751  1.009  1.027      0.85\n",
       "3        Xgboost   7.875  32.869  1.738  1.135      0.75"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee1e0b",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1308e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_dict = {}\n",
    "\n",
    "for model_type, model_results in search_results.items():\n",
    "    if model_results['package_type'] == 'sktime':\n",
    "        best_model = search_results[model_type]['best_model']\n",
    "        best_model.fit(y=optimal_df['y'])\n",
    "        predictions = generate_forecast_sktime(best_model, run_params['forecast_period'])\n",
    "    elif model_results['package_type'] == 'skforecast':\n",
    "        best_model = search_results[model_type]['best_model']\n",
    "        best_model.fit(y=optimal_df['y'], exog=optimal_df[run_params[\"exog_cols_all\"]])\n",
    "        predictions = generate_forecast_skforecast(best_model, run_params, optimal_df['y'],\n",
    "                                                                 forecast_df.drop('y', axis=1),\n",
    "                                                                 run_params[\"forecast_start_date\"],\n",
    "                                                                 run_params['forecast_period'])\n",
    "    else:\n",
    "        raise Exception('Unknown package type!')\n",
    "        \n",
    "    forecasts_dict[model_type] = predictions.head(run_params['forecast_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'prophet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30134d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant data from the historical and forecast DataFrames\n",
    "historical_data = optimal_df.reset_index()[['ds', 'y']]\n",
    "forecast_data = forecasts_dict[model_type][['ds', 'y_pred', 'min_pred', 'max_pred']]\n",
    "fig = plot_forecasts(historical_data, forecast_data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cdf68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data['type'] = 0 # 1 for historical\n",
    "forecast_data['type'] = 1  # 1 for forecast\n",
    "# Prepare forecast data\n",
    "forecast_data['y'] = forecast_data['y_pred']\n",
    "forecast_data = forecast_data.drop(columns=['y_pred'])\n",
    "\n",
    "# Merge the two DataFrames\n",
    "combined_data = pd.concat([historical_data, forecast_data], sort=True)\n",
    "\n",
    "# Sort by date if necessary\n",
    "combined_data = combined_data.sort_values(by='ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0622d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_types = ['month', 'day_of_week', 'week_of_year']\n",
    "agg_types = ['mean', 'sum', 'min', 'max']\n",
    "selected_freq = freq_types[1]\n",
    "selected_agg = agg_types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = create_pivot_table(combined_data, selected_freq, selected_agg)\n",
    "fig = plot_time_series(pivot_table)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
